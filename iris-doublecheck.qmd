---
title: "commit-file"
format:
  html:
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

# R libs

```{r}
library(reticulate)
library(DT)
use_python("~/opt/miniconda3/envs/omb/bin/python3.9")
```

## Python imports

```{python}
import os
import base64
import gitlab
import pandas as pd
import re
from dfply import *
import yaml
from datetime import datetime
```


## Read private token

N.B.: gitlab token must be stored (alone) in a file called `.token`.

```{python}
tf = open(".token", "r")
token = tf.read().rstrip()
tf.close()

n = len(token)
print(token[0:5], "...", token[n-5:n], sep="")
```

## Vars to define what we want to scrape


```{python}
search_terms = ["iris"]

target_branches = ["master","main"]

target = ["requirements.txt", "Dockerfile"]
colnames = ["omnibenchmark_version", "renku_version"]
target_path = [".","."]
target_pkg = ["omnibenchmark", "ARG RENKU_VERSION"]
separ = ["==", "="]
new_ver = ["0.0.39", "1.11.2"]


# datetime object containing current date and time
now = datetime.now()
print("now =", now)
dt_string = now.strftime("%d/%m/%Y %H:%M:%S")
# https://www.programiz.com/python-programming/datetime/current-datetime
```


## Grab a set of projects according to search terms

```{python}
gl = gitlab.Gitlab(url='https://renkulab.io/gitlab',private_token=token)
print(gl.api_url)

projects = []
for term in search_terms:
    projects.extend(gl.projects.list(get_all=True, search=term,
                                     order_by="last_activity_at", per_page=100))

print(len(projects))

# get unique list
projects_uniq = []
for item in projects:
    if item not in projects_uniq:
        projects_uniq.append(item)

print(len(projects_uniq))

```

## Grab stuff out of every project

In this example, look only into `iris` projects, parse the `requirements.txt` and `Dockerfile` files and pull out particular versions.

```{python}
z = [None] * len(projects_uniq)

for i in range(len(projects_uniq)):
    p = projects_uniq[i]
    bs = p.branches.list(get_all=True)
    bb = [b.name for b in bs if b.name in target_branches]
    if len(bb)==0:
        continue
    br = bb[0]
    vers = ["",""]
    for j in range(len(target_path)):
        fs = p.repository_tree(path=target_path[j], ref=br, all=True)
        cy = [f["path"] for f in fs if f["path"] == target[j]]
        cy = ''.join(cy)
        url = p.http_url_to_repo.replace("https://renkulab.io/gitlab/","")
        url = re.sub(".git$","", url)
        if(cy == target[j]):
            f = p.files.get(file_path=target[j], ref=br)
            fc = base64.b64decode(f.content).decode("utf-8")
            fc = fc.replace('\\n', '\n')
            pkgs_list = fc.split("\n")
            ver = [re.split(separ[j], pkg) for pkg in pkgs_list if re.search(target_pkg[j], pkg)]
            if(len(ver)>0):
                vers[j] = ver[0][1]
            else:
                vers[j] = ""
    z[i] = [p.id, url, br, vers[0], vers[1]]

# get clean list
z_clean = []
for item in z:
    if item is not None:
        z_clean.append(item)

print(len(z_clean))
```

## Format into a pandas DataFrame and have a look

```{python}
pd.options.display.max_colwidth = 60
df = pd.DataFrame(z_clean, columns=['id','url_snippet','branch', 
                                    colnames[0],colnames[1]])
print(df >> arrange(X.omnibenchmark_version))
```


## Tabular summary

```{r}
DT::datatable(py$df)
```

## Update all the `requirements.txt` files

```{python}
# df = df[df['omnibenchmark_version']!=""]

# function to manipulate version numbers
def update_version(fc, target_pkg, separator, new_val):
    fcs = [pkg.split(separator) for pkg in fc.split("\n")]
    for i in range(len(fcs)):
      if(fcs[i][0] == target_pkg):
        fcs[i][1] = new_val
    fc_adj = "\n".join([separator.join(ii) for ii in fcs])
    return(fc_adj)

# function to create JSON commit info
def create_commit_JSON(action, content, path, msg, branch):
    data = {
        'branch': branch,
        'commit_message': msg,
        'actions': [
            {
                'action': action,
                'file_path': path,
                'content': content, # NOTE: local file
            }
        ]
    }
    return(data)

# loop through repos, modify version
for ii in range(len(df)):
    for jj in range(len(target)):
        if(df[colnames[jj]][ii]==''):
          continue
        p = projects_uniq[df.index[ii]] # get project from earlier list
        url = p.http_url_to_repo.replace("https://renkulab.io/gitlab/","")
        try:
          dummy = p.accessrequests.list()
          print("\nYes, have access to:" + url)
        except:
          print("\nNo access to:" + url)
          continue
        br = df['branch'][ii]
        fs = p.repository_tree(path=target_path[jj], ref=br, all=True)
        cy = [f["path"] for f in fs if f["path"] == target[jj]]
        cy = ''.join(cy)
        if cy==target[jj]:
          f = p.files.get(file_path=target[jj], ref=br)
          fc = base64.b64decode(f.content).decode("utf-8")
          fc_adj = update_version(fc, target_pkg[jj],
                                  new_val=new_ver[jj], separator=separ[jj])
          com = create_commit_JSON('update', fc_adj, target[jj],
                                  "update '" + target_pkg[jj] + "' to: " + new_ver[jj],
                                  br)
          commit = p.commits.create(com)
          print(cy)
          print(com['commit_message'])
          print(commit.id)

```


## sessionInfo-python

```{python}
import session_info
session_info.show()
```


## sessionInfo-R

```{r}
sessionInfo()
```

